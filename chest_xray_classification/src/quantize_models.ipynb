{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NIH_14_DATASET_PATH = '../NIH_14/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_path = os.path.abspath(NIH_14_DATASET_PATH)\n",
    "os.listdir(dataset_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_entry_csv_path = os.path.join(dataset_path, 'Data_Entry_2017.csv')\n",
    "data = pd.read_csv(data_entry_csv_path)\n",
    "print(f\"Data Shape : {data.shape}\")\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data[data['Patient Age']<100]\n",
    "\n",
    "print(f\"New dataset dimensions: {data.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data[['Image Index', 'Finding Labels']]\n",
    "print(data.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_images = sorted(glob2.glob(dataset_path + '/**/*.png'))\n",
    "print(f'Number of Images: {len(all_images)}')\n",
    "\n",
    "all_image_paths = {os.path.basename(x): x for x in all_images}\n",
    "\n",
    "#Add path of images as column to the dataset\n",
    "data['Path'] = data['Image Index'].map(all_image_paths.get)\n",
    "data.sample(5, random_state=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "print(all_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_labels = np.delete(all_labels, np.where(all_labels == 'No Finding'))\n",
    "all_labels = [x for x in all_labels]\n",
    "all_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        # Add a column for each desease\n",
    "        data[c_label] = data['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
    "        \n",
    "print(f\"Dataset Dimension: {data.shape}\")\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_counts = data['Finding Labels'].value_counts()\n",
    "label_counts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data.groupby('Finding Labels').filter(lambda x : len(x)>11)\n",
    "label_counts = data['Finding Labels'].value_counts()\n",
    "print(label_counts.shape)\n",
    "print(label_counts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_and_valid_df, test_df = train_test_split(data,\n",
    "                                               test_size = 0.30,\n",
    "                                               random_state = 2018,\n",
    "                                              )\n",
    "\n",
    "train_df, valid_df = train_test_split(train_and_valid_df,\n",
    "                                      test_size=0.30,\n",
    "                                      random_state=2018,\n",
    "                                     )\n",
    "\n",
    "print(f'Training: {train_df.shape[0]} Validation: {valid_df.shape[0]} Testing: {test_df.shape[0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_generator = ImageDataGenerator(rescale=1./255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "def flow_from_dataframe(image_generator, dataframe, batch_size):\n",
    "\n",
    "    df_gen = image_generator.flow_from_dataframe(dataframe,\n",
    "                                                 x_col='Path',\n",
    "                                                 y_col=all_labels,\n",
    "                                                 target_size=IMG_SIZE,\n",
    "                                                 classes=all_labels,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='raw',\n",
    "                                                 shuffle=False,\n",
    "                                                 batch_size=batch_size)\n",
    "    \n",
    "    return df_gen"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_gen = flow_from_dataframe(image_generator=base_generator, \n",
    "                                dataframe= train_df,\n",
    "                                batch_size = 3)\n",
    "\n",
    "valid_gen = flow_from_dataframe(image_generator=base_generator, \n",
    "                                dataframe=valid_df,\n",
    "                                batch_size = 3)\n",
    "\n",
    "test_gen = flow_from_dataframe(image_generator=base_generator, \n",
    "                               dataframe=test_df,\n",
    "                               batch_size = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_x, train_y = next(train_gen)\n",
    "print(f\"Image Dimensions: {train_x[1].shape}\")\n",
    "print(f\"Labels: {train_y[1]}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape=(224, 224, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "base_model = DenseNet121(include_top=False, input_tensor=img_input, input_shape=input_shape, \n",
    "                         pooling=\"avg\", weights='imagenet')\n",
    "x = base_model.output\n",
    "\n",
    "predictions = Dense(len(all_labels), activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "model = Model(inputs=img_input, outputs=predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from post_training_qunantization import ModelOptimization"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_optimization_instance = ModelOptimization()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_optimization_instance.weight_file_path = os.path.abspath('./weights/baseline_FP32.h5')\n",
    "model_optimization_instance.model = model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Dynamic Quantization...\")\n",
    "model_optimization_instance.dynamic_quantization()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"FP-16 Quantization...\")\n",
    "model_optimization_instance.fp_16_quantization()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(500):\n",
    "        yield [next(valid_gen)[0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "quantize_annotate_model = tfmot.quantization.keras.quantize_annotate_model\n",
    "quantize_scope = tfmot.quantization.keras.quantize_scope"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DefaultBNQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return []\n",
    "    \n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        return []\n",
    "    \n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        pass\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        pass\n",
    "\n",
    "    def get_output_quantizers(self, layer):\n",
    "        return [tfmot.quantization.keras.quantizers.MovingAverageQuantizer(\n",
    "    num_bits=8, per_axis=False, symmetric=False, narrow_range=False)]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def apply_quantization_to_batch_normalization(layer):\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        return quantize_annotate_layer(layer, DefaultBNQuantizeConfig())\n",
    "    \n",
    "    return layer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "annotated_model = tf.keras.models.clone_model(\n",
    "                    model,\n",
    "                    clone_function=apply_quantization_to_batch_normalization,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with quantize_scope(\n",
    "  {'DefaultBNQuantizeConfig': DefaultBNQuantizeConfig}):\n",
    "  # Use `quantize_apply` to actually make the model quantization aware.\n",
    "  quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_optimization_instance.model = quant_aware_model\n",
    "model_optimization_instance.weight_file_path = os.path.abspath('./weights/baseline_QAT_FP32.h5')\n",
    "model_optimization_instance.representative_dataset = representative_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('INT-8 Quantization...')\n",
    "model_optimization_instance.int_8_quantization()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}