{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "NIH_14_DATASET_PATH = '../NIH_14/'\n",
    "dataset_path = os.path.abspath(NIH_14_DATASET_PATH)\n",
    "assert os.path.exists(dataset_path)\n",
    "os.listdir(dataset_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "data_entry_csv_path = os.path.join(dataset_path, 'Data_Entry_2017.csv')\n",
    "data = pd.read_csv(data_entry_csv_path)\n",
    "print(f\"Data Shape : {data.shape}\")\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Removing patients with age greater than 100\n",
    "data = data[data['Patient Age']<100]\n",
    "\n",
    "print(f\"New dataset dimensions: {data.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data[['Image Index', 'Finding Labels']]\n",
    "print(data.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import glob2\n",
    "\n",
    "all_images = sorted(glob2.glob(dataset_path + '/**/*.png'))\n",
    "print(f'Number of Images: {len(all_images)}')\n",
    "\n",
    "all_image_paths = {os.path.basename(x): x for x in all_images}\n",
    "\n",
    "#Add path of images as column to the dataset\n",
    "data['Path'] = data['Image Index'].map(all_image_paths.get)\n",
    "data.sample(5, random_state=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "print(all_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_labels = np.delete(all_labels, np.where(all_labels == 'No Finding'))\n",
    "all_labels = [x for x in all_labels]\n",
    "all_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        # Add a column for each desease\n",
    "        data[c_label] = data['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
    "        \n",
    "print(f\"Dataset Dimension: {data.shape}\")\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_counts = data['Finding Labels'].value_counts()\n",
    "label_counts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data.groupby('Finding Labels').filter(lambda x : len(x)>11)\n",
    "label_counts = data['Finding Labels'].value_counts()\n",
    "print(label_counts.shape)\n",
    "print(label_counts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_and_valid_df, test_df = train_test_split(data,\n",
    "                                               test_size = 0.30,\n",
    "                                               random_state = 2018,\n",
    "                                              )\n",
    "\n",
    "train_df, valid_df = train_test_split(train_and_valid_df,\n",
    "                                      test_size=0.30,\n",
    "                                      random_state=2018,\n",
    "                                     )\n",
    "\n",
    "print(f'Training: {train_df.shape[0]} Validation: {valid_df.shape[0]} Testing: {test_df.shape[0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_image_paths = test_df['Path'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save images to test_images directory. This will be copied to coral dev baord for the inference purpose.\n",
    "dst_dir = os.path.abspath('./test_images/')\n",
    "\n",
    "if not os.path.exists(dst_dir):\n",
    "    os.makedirs(dst_dir)\n",
    "\n",
    "for img_path_item in test_image_paths:\n",
    "    src = img_path_item\n",
    "    base_name = img_path_item.split('/')[-1]\n",
    "    dst = os.path.join(dst_dir, base_name)\n",
    "    shutil.copy(src, dst)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df = test_df[['Path', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', \n",
    "                   'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "actual_labels = dict()\n",
    "for idx, row in test_df.iterrows():\n",
    "    actual_labels[row[0]] = list(row[1:].values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save actual labels in json file. This will be compared with predictions on edge tpu for calculation of AUC score.\n",
    "with open('actual.json', 'w') as actual_file:\n",
    "    json.dump(actual_labels, actual_file)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}