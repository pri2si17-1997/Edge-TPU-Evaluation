{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.test.is_gpu_available()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def check_dict_subset(subset, superset):\n",
    "    \"\"\"Checks if one nested dictionary is a subset of another\n",
    "\n",
    "    :param subset: subset dictionary\n",
    "    :param superset: superset dictionary\n",
    "    :return: if failed: gives helpful print statements and assertion error\n",
    "             if successful, prints 'Your parameter choice is valid'\n",
    "    \"\"\"\n",
    "    print(\"superset keys:\", superset.keys())\n",
    "    print(\"subset keys:\", subset.keys())\n",
    "    assert all(item in superset.keys() for item in subset.keys())\n",
    "    print(\"Subset keys is a subset of superset keys\", all(item in superset.keys() for item in subset.keys()))\n",
    "    for key in subset.keys():\n",
    "        print(\"superset key items:\", superset[key])\n",
    "        print(\"subset key items:\", subset[key])\n",
    "        if type(superset[key]) == dict:\n",
    "            assert type(subset[key]) == type(superset[key])\n",
    "            check_dict_subset(subset[key], superset[key])\n",
    "        elif type(superset[key]) == list:\n",
    "            assert subset[key] in superset[key]\n",
    "            print(\"subset[key] item:\", subset[key], \" is in superset[key] items:\", superset[key])\n",
    "        else:\n",
    "            print(\"Something went wrong. Uncomment the print statements in check_dict_subset() for easier debugging.\")\n",
    "            return type(superset[key]), superset[key]\n",
    "\n",
    "    return 'Your parameter choice is valid'\n",
    "\n",
    "\n",
    "# Only change ALLOWED_PARS if adding new functionality\n",
    "ALLOWED_PARS = {\n",
    "    'outputs': [1, 2],\n",
    "    'activation': ['elu', 'relu'],\n",
    "    'pooling_block': {\n",
    "        'trainable': [True, False]},\n",
    "    'information_block': {\n",
    "        'inception': {\n",
    "            'v1': ['a', 'b'],\n",
    "            'v2': ['a', 'b', 'c'],\n",
    "            'et': ['a', 'b']},\n",
    "        'convolution': {\n",
    "            'simple': ['not_normalized', 'normalized'],\n",
    "            'dilated': ['not_normalized', 'normalized']}},\n",
    "    'connection_block': ['not_residual', 'residual']\n",
    "}\n",
    "\n",
    "# for reference: in combination, these parameter choice showed the best performance\n",
    "BEST_OPTIMIZER = Adam(lr=0.0045)\n",
    "BEST_PARS = {\n",
    "    'outputs': 2,\n",
    "    'activation': 'elu',\n",
    "    'pooling_block': {'trainable': True},\n",
    "    'information_block': {'inception': {'v2': 'b'}},\n",
    "    'connection_block': 'residual'\n",
    "}\n",
    "\n",
    "print(check_dict_subset(BEST_PARS, ALLOWED_PARS))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(ALLOWED_PARS)\n",
    "\n",
    "# The result is very sensitive to the choice of the Learning Rate parameter  of the optimizer\n",
    "# DO NOT CHANGE THE NAME, you can change the parameters\n",
    "OPTIMIZER = Adam(lr=0.0045)\n",
    "\n",
    "# DO NOT CHANGE THE NAME, you can change the parameters\n",
    "PARS = {\n",
    "    'outputs': 1,\n",
    "    'activation': 'relu',\n",
    "    'pooling_block': {'trainable': False},\n",
    "    'information_block': {'convolution': {'simple': 'normalized'}},\n",
    "    'connection_block': 'not_residual'\n",
    "}\n",
    "\n",
    "# DO NOT REMOVE THESE LINES, they checks if your parameter choice is valid\n",
    "assert PARS.keys() == ALLOWED_PARS.keys()\n",
    "print(check_dict_subset(PARS, ALLOWED_PARS))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "\n",
    "_dir = os.path.abspath(os.getcwd())\n",
    "os.chdir(_dir)\n",
    "print(_dir)\n",
    "\n",
    "print(os.listdir(_dir))\n",
    "print(os.listdir(\"../dataset/\"))\n",
    "print(os.listdir(\"../dataset/\"))\n",
    "\n",
    "# data\n",
    "data_path = os.path.join('../dataset/', '')\n",
    "preprocess_path = os.path.join(_dir, 'np_data')\n",
    "\n",
    "if not os.path.exists(preprocess_path):\n",
    "    os.mkdir(preprocess_path)\n",
    "print(os.listdir(_dir))\n",
    "\n",
    "# train data\n",
    "img_train_path = os.path.join(preprocess_path, 'imgs_train.npy')\n",
    "img_train_mask_path = os.path.join(preprocess_path, 'imgs_mask_train.npy')\n",
    "img_train_patients = os.path.join(preprocess_path, 'imgs_patient.npy')\n",
    "img_nerve_presence = os.path.join(preprocess_path, 'nerve_presence.npy')\n",
    "\n",
    "# test data\n",
    "img_test_path = os.path.join(preprocess_path, 'imgs_test.npy')\n",
    "img_test_id_path = os.path.join(preprocess_path, 'imgs_id_test.npy')\n",
    "\n",
    "# image dimensions\n",
    "image_rows = 420\n",
    "image_cols = 580\n",
    "\n",
    "\n",
    "# ======================================================================================================================\n",
    "# Functions for test and train data creation, storage and access\n",
    "# ======================================================================================================================\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"Load test data from a .npy file.\n",
    "\n",
    "    :return: np.array with test data.\n",
    "    \"\"\"\n",
    "    print('Loading test data from %s' % img_test_path)\n",
    "    imgs_test = np.load(img_test_path)\n",
    "    return imgs_test\n",
    "\n",
    "\n",
    "def load_test_ids():\n",
    "    \"\"\"Load test ids from a .npy file.\n",
    "\n",
    "    :return: np.array with test ids. Shape (samples, ).\n",
    "    \"\"\"\n",
    "    print('Loading test ids from %s' % img_test_id_path)\n",
    "    imgs_id = np.load(img_test_id_path)\n",
    "    return imgs_id\n",
    "\n",
    "\n",
    "def load_train_data():\n",
    "    \"\"\"Load train data from a .npy file.\n",
    "\n",
    "    :return: np.array with train data.\n",
    "    \"\"\"\n",
    "    print('Loading train data from %s and %s' % (img_train_path, img_train_mask_path))\n",
    "    imgs_train = np.load(img_train_path)\n",
    "    imgs_mask_train = np.load(img_train_mask_path)\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "\n",
    "def load_patient_num():\n",
    "    \"\"\"Load the array with patient numbers from a .npy file\n",
    "\n",
    "    :return: np.array with patient numbers\n",
    "    \"\"\"\n",
    "    print('Loading patient numbers from %s' % img_train_patients)\n",
    "    return np.load(img_train_patients)\n",
    "\n",
    "\n",
    "def load_nerve_presence():\n",
    "    \"\"\"Load the array with binary nerve presence from a .npy file\n",
    "\n",
    "    :return: np.array with patient numbers\n",
    "    \"\"\"\n",
    "    print('Loading nerve presence array from %s' % img_nerve_presence)\n",
    "    return np.load(img_nerve_presence)\n",
    "\n",
    "\n",
    "def get_patient_nums(string):\n",
    "    \"\"\"Create a tuple (patient, photo) from image-file name patient_photo.tif\n",
    "\n",
    "    :param string: image-file name in string format: patient_photo.tif\n",
    "    :return: a tuple (patient, photo)\n",
    "\n",
    "    >>> get_patient_nums('32_50.tif')\n",
    "    (32, 50)\n",
    "    \"\"\"\n",
    "    patient, photo = string.split('_')\n",
    "    photo = photo.split('.')[0]\n",
    "    return int(patient), int(photo)\n",
    "\n",
    "\n",
    "def get_nerve_presence(mask_array):\n",
    "    \"\"\"Create an array specifying nerve presence on each of the masks in the mask_array\n",
    "\n",
    "    :param mask_array: 4D tensor of a shape (samples, rows, cols, channels=1) with masks\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"type(mask_array):\", type(mask_array))\n",
    "    print(\"mask_array.shape:\", mask_array.shape)\n",
    "    return np.array([int(np.sum(mask_array[i, :, :, 0]) > 0) for i in range(mask_array.shape[0])])\n",
    "\n",
    "\n",
    "def create_train_data():\n",
    "    \"\"\"\n",
    "    Create an np.array with patient numbers and save it into a .npy file.\n",
    "    Create an np.array with train images and save it into a .npy file.\n",
    "    Create an np.array with train masks and save it into a .npy file.\n",
    "\n",
    "    The np.array with patient numbers will have shape (samples, ).\n",
    "        So for each train image saved, the patient number will be recorded exactly in the same order the\n",
    "        images were saved.\n",
    "    The np.array with train images will have shape (samples, rows, cols, channels).\n",
    "    The np.array with train masks will have shape (samples, rows, cols, channels).\n",
    "        The masks are saved in the same order as the images.\n",
    "    \"\"\"\n",
    "    train_data_path = os.path.join(data_path, 'train')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images) // 2\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols, 1), dtype=np.uint8)\n",
    "    imgs_mask = np.ndarray((total, image_rows, image_cols, 1), dtype=np.uint8)\n",
    "    i = 0\n",
    "    print('Creating training images...')\n",
    "    img_patients = np.ndarray((total,), dtype=np.uint8)\n",
    "    for image_name in images:\n",
    "\n",
    "        # With \"continue\" skip the mask image in the iteration because the mask will be saved together with\n",
    "        # the image, when we get the image in one of the next iterations. This guarantees that the images,\n",
    "        # masks and corresponding patient numbers are all saved in the correct order.\n",
    "        if 'mask' in image_name:\n",
    "            continue\n",
    "\n",
    "        # we got to this point, meaning that image_name is a name of a training image and not a mask.\n",
    "\n",
    "        # recreate the mask's name fot this image\n",
    "        # noinspection PyTypeChecker\n",
    "        image_mask_name = image_name.split('.')[0] + '_mask.tif'\n",
    "        # get the patient number of the image\n",
    "        patient_num = image_name.split('_')[0]\n",
    "        # read the image itself to an np.array\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_gray=True)\n",
    "        # read the corresponding mask to an np.array\n",
    "        img_mask = imread(os.path.join(train_data_path, image_mask_name), as_gray=True)\n",
    "\n",
    "        imgs[i, :, :, 0] = img\n",
    "        imgs_mask[i, :, :, 0] = img_mask\n",
    "        img_patients[i] = patient_num\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    # saving patient numbers, train images, train masks, nerve presence\n",
    "    np.save(img_train_patients, img_patients)\n",
    "    np.save(img_train_path, imgs)\n",
    "    np.save(img_train_mask_path, imgs_mask)\n",
    "    np.save(img_nerve_presence, get_nerve_presence(imgs_mask))\n",
    "\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    \"\"\"\n",
    "    Create an np.array with test data and save it into a .npy file.\n",
    "    Create an np.array with ids for all images and save it into a .npy file.\n",
    "\n",
    "    The np.array with test data will have shape (samples, rows, cols, channels).\n",
    "    The np.array with test data ids will have shape (samples,). Each image id will be a number\n",
    "    corresponding to the number in a test image name. For example image '8.tif' will have 8 as its image id.\n",
    "    \"\"\"\n",
    "    test_data_path = os.path.join(data_path, 'test')\n",
    "    images = os.listdir(test_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols, 1), dtype=np.uint8)\n",
    "    imgs_id = np.ndarray((total,), dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    print('Creating test images...')\n",
    "    for image_name in images:\n",
    "        img_id = int(image_name.split('.')[0])\n",
    "        img = imread(os.path.join(test_data_path, image_name), as_gray=True)\n",
    "\n",
    "        imgs[i, :, :, 0] = img\n",
    "        imgs_id[i] = img_id\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save(img_test_path, imgs)\n",
    "    np.save(img_test_id_path, imgs_id)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "create_train_data()\n",
    "create_test_data()\n",
    "\n",
    "print(os.listdir(preprocess_path))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import backend as K  # tensorflow backend\n",
    "\n",
    "\n",
    "def dice_coef(mask_1, mask_2, smooth=1):\n",
    "    \"\"\"Compute the dice coefficient between two equal-sized masks.\n",
    "\n",
    "    Dice Coefficient: https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "    We need to add smooth, because otherwise 2 empty (all zeros) masks will throw an error instead of\n",
    "    giving 1 as an output.\n",
    "\n",
    "    :param mask_1: first mask\n",
    "    :param mask_2: second mask\n",
    "    :param smooth: Smoothing parameter for dice coefficient\n",
    "    :return: Smoothened dice coefficient between two equal-sized masks\n",
    "    \"\"\"\n",
    "    mask_1_flat = K.flatten(mask_1)\n",
    "    mask_2_flat = K.flatten(mask_2)\n",
    "\n",
    "    # for pixel values in {0, 1} multiplication is the intersection of masks\n",
    "    intersection = K.sum(mask_1_flat * mask_2_flat)\n",
    "    return (2. * intersection + smooth) / (K.sum(mask_1_flat) + K.sum(mask_2_flat) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(mask_pred, mask_true):\n",
    "    \"\"\"Calculate dice coefficient loss, when comparing predicted mask for an image with the true mask\n",
    "\n",
    "    :param mask_pred: predicted mask\n",
    "    :param mask_true: true mask\n",
    "    :return: dice coefficient loss\n",
    "    \"\"\"\n",
    "    return -dice_coef(mask_pred, mask_true)\n",
    "\n",
    "\n",
    "def np_dice_coef(mask_1, mask_2, smooth=1):\n",
    "    \"\"\"Compute the dice coefficient between two equal-sized masks.\n",
    "\n",
    "    Used for testing on artificially generated np.arrays\n",
    "\n",
    "    Dice Coefficient: https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "    Need smooth, because otherwise 2 empty (all zeros) masks will throw an error instead of giving 1 as an output.\n",
    "\n",
    "    :param mask_1: first mask\n",
    "    :param mask_2: second mask\n",
    "    :param smooth: Smoothing parameter for dice coefficient\n",
    "    :return: Smoothened dice coefficient between two equal-sized masks\n",
    "    \"\"\"\n",
    "    tr = mask_1.flatten()\n",
    "    pr = mask_2.flatten()\n",
    "    return (2. * np.sum(tr * pr) + smooth) / (np.sum(tr) + np.sum(pr) + smooth)\n",
    "\n",
    "#Testing dice coefficient \n",
    "a = np.random.random((420, 100))\n",
    "b = np.random.random((420, 100))\n",
    "res = np_dice_coef(a, b)\n",
    "print(res)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers import add, concatenate, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Lambda\n",
    "from tensorflow.keras.layers import ELU, LeakyReLU\n",
    "\n",
    "def NConv2D(filters, kernel_size, strides=(1, 1), padding='valid', dilation_rate=1,\n",
    "            activation=None, kernel_initializer='glorot_uniform'):\n",
    "    \"\"\"Create a (Normalized Conv2D followed by a chosen activation) function\n",
    "    Conv2D -> BatchNormalization -> activation()\n",
    "\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "    convolution)\n",
    "    :param kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution\n",
    "                        window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    :param strides: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height\n",
    "                    and width. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "                    Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
    "    :param padding: one of 'valid' or 'same' (case-insensitive), 'valid' by default to have the same as Conv2D\n",
    "    :param dilation_rate: an integer or tuple/list of a single integer, specifying the dilation rate\n",
    "                    to use for dilated convolution. Currently, specifying any dilation_rate value != 1\n",
    "                    is incompatible with specifying any strides value != 1\n",
    "    :param activation:  string, one of 'elu' or 'relu' or None (case-sensitive),\n",
    "                        specifies activation function to be performed after BatchNormalization\n",
    "    :param kernel_initializer: Initializer for the kernel weights matrix (see initializers in keras documentation)\n",
    "    :return: a function, combined of 2D Convolution, followed by BatchNormalization across filters,\n",
    "             and specified activation in that order\n",
    "    \"\"\"\n",
    "    assert activation in ['relu', 'elu', None]\n",
    "    # actv is a function, not a string, like activation\n",
    "    actv = activation == 'relu' and (lambda: LeakyReLU(0.0)) or activation == 'elu' and (lambda: ELU(1.0)) or None\n",
    "\n",
    "    def f(_input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                      dilation_rate=dilation_rate, kernel_initializer=kernel_initializer)(_input)\n",
    "        norm = BatchNormalization(axis=3)(conv)\n",
    "        return actv()(norm)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# needed for rblock (residual block)\n",
    "def _shortcut(_input, residual):\n",
    "    stride_width = _input._keras_shape[1] / residual._keras_shape[1]\n",
    "    stride_height = _input._keras_shape[2] / residual._keras_shape[2]\n",
    "    equal_channels = residual._keras_shape[3] == _input._keras_shape[3]\n",
    "\n",
    "    shortcut = _input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual._keras_shape[3], kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          kernel_initializer=\"he_normal\", padding=\"valid\")(_input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def rblock(inputs, filters, kernel_size, padding='valid', activation=None, scale=0.1):\n",
    "    \"\"\"Create a scaled Residual block connecting the down-path and the up-path of the u-net architecture\n",
    "\n",
    "    Activations are scaled by a constant to prevent the network from dying. Usually is set between 0.1 and 0.3. See:\n",
    "    https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202\n",
    "\n",
    "    :param inputs: Input 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output convolution filters)\n",
    "    :param kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution\n",
    "                        window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    :param padding: one of 'valid' or 'same' (case-insensitive), 'valid' by default to have the same as Conv2D\n",
    "    :param activation:  string, one of 'elu' or 'relu' or None (case-sensitive),\n",
    "                        specifies activation function to use everywhere in the block\n",
    "    :param scale: scaling factor preventing the network from dying out\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of a residual block, given inputs\n",
    "    \"\"\"\n",
    "    assert activation in ['relu', 'elu', None]\n",
    "    # actv is a function, not a string, like activation\n",
    "    actv = activation == 'relu' and (lambda: LeakyReLU(0.0)) or activation == 'elu' and (lambda: ELU(1.0)) or None\n",
    "\n",
    "    residual = Conv2D(filters=filters, kernel_size=kernel_size, padding=padding)(inputs)\n",
    "    residual = BatchNormalization(axis=3)(residual)\n",
    "    residual = Lambda(lambda x: x * scale)(residual)\n",
    "    res = _shortcut(inputs, residual)\n",
    "    return actv()(res)\n",
    "\n",
    "\n",
    "# ======================================================================================================================\n",
    "# information blocks\n",
    "# ======================================================================================================================\n",
    "\n",
    "def convolution_block(inputs, filters, kernel_size=(3, 3), padding='valid', activation=None,\n",
    "                      version='normalized', pars={}, allowed_pars={}):\n",
    "    \"\"\"Create a version of a convolution block.\n",
    "\n",
    "    Versions: with and without batch-normalization after convolutions.\n",
    "\n",
    "    :param inputs: Input 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "                    convolution).\n",
    "    :param kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution\n",
    "                        window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    :param padding: one of 'valid' or 'same' (case-insensitive), 'valid' by default to have the same as Conv2D\n",
    "    :param activation: string, specifies activation function to use everywhere in the block\n",
    "    :param version: version of the convolution block, one of 'not_normalized', 'normalized' (case sensitive)\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version, if this type of block is chosen\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of a convolution block, given inputs\n",
    "    \"\"\"\n",
    "    assert activation in ['relu', 'elu', None]\n",
    "\n",
    "    # checking that the allowed version names did not change in ALLOWED_PARS\n",
    "    if allowed_pars != {}:\n",
    "        assert allowed_pars.get('information_block').get('convolution').get('simple') == ['not_normalized',\n",
    "                                                                                          'normalized']\n",
    "    # keep version argument if need to use without PARS\n",
    "    assert version in ['not_normalized', 'normalized']\n",
    "    # setting the version from pars\n",
    "    if pars.get('information_block').get('convolution').get('simple') is not None:\n",
    "        version = pars.get('information_block').get('convolution').get('simple')\n",
    "\n",
    "    if version == 'normalized':\n",
    "        conv1 = NConv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(inputs)\n",
    "        return NConv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv1)\n",
    "    else:\n",
    "        conv1 = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(inputs)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv1)\n",
    "\n",
    "\n",
    "def dilated_convolution_block(inputs, filters, kernel_size=(3, 3), padding='valid', activation=None,\n",
    "                              version='normalized', pars={}, allowed_pars={}):\n",
    "    \"\"\"Create a version of a dilated-convolution block.\n",
    "\n",
    "    Versions: with and without batch-normalization after dilated convolutions.\n",
    "\n",
    "    See more about dilated convolutions:\n",
    "    https://towardsdatascience.com/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5\n",
    "\n",
    "    :param inputs: Input 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "                    convolution).\n",
    "    :param kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution\n",
    "                        window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    :param padding: one of 'valid' or 'same' (case-insensitive), 'valid' by default to have the same as Conv2D\n",
    "    :param activation: string, specifies activation function to use everywhere in the block\n",
    "    :param version: version of the dilated-convolution block, one of 'not_normalized', 'normalized' (case sensitive)\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version, if this type of block is chosen\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of a dilated-convolution block, given inputs\n",
    "    \"\"\"\n",
    "    assert activation in ['relu', 'elu', None]\n",
    "\n",
    "    # checking that the allowed version names did not change in ALLOWED_PARS\n",
    "    if allowed_pars != {}:\n",
    "        assert allowed_pars.get('information_block').get('convolution').get('dilated') == ['not_normalized',\n",
    "                                                                                           'normalized']\n",
    "    # keep version argument if need to use without PARS\n",
    "    assert version in ['not_normalized', 'normalized']\n",
    "    # setting the version from pars\n",
    "    if pars.get('information_block').get('convolution') is not None:\n",
    "        version = pars.get('information_block').get('convolution')\n",
    "\n",
    "    if version == 'normalized':\n",
    "        conv1 = NConv2D(filters=filters, kernel_size=kernel_size, padding=padding,\n",
    "                        dilation_rate=2, activation=activation)(inputs)\n",
    "        return NConv2D(filters=filters, kernel_size=kernel_size, padding=padding,\n",
    "                       dilation_rate=1, activation=activation)(conv1)\n",
    "    else:\n",
    "        conv1 = Conv2D(filters=filters, kernel_size=kernel_size, padding=padding,\n",
    "                       dilation_rate=2, activation=activation)(inputs)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size, padding=padding,\n",
    "                      dilation_rate=1, activation=activation)(conv1)\n",
    "\n",
    "\n",
    "def inception_block_v1(inputs, filters, activation=None, version='b', pars={}, allowed_pars={}):\n",
    "    \"\"\"Create a version of v1 inception block described in:\n",
    "    https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202\n",
    "\n",
    "    Create an inception block described in v1, sections 'a' (for naive version), or 'b' (with dimension reduction)\n",
    "    Each version has 4 verticals in their structure. See the link above.\n",
    "\n",
    "    For all versions, verticals 1 and 2 of the block start with 2D convolution, which:\n",
    "        reduces the number of input filters to next convolutions (to make computation cheaper)\n",
    "        uses (1, 1) kernels, no Normalization\n",
    "        is NOT normalized\n",
    "        is followed by specified activation\n",
    "    For all versions, verticals 1, 2, 3:\n",
    "        the final convolution layer is not normalised and not activated since it will be dene after concatenation\n",
    "    Vertical 4 is just a Conv2D. Its gets normalized and activated after being concatenated with\n",
    "        outputs of other verticals.\n",
    "    The concatenated output of the verticals is normalised and then activated with a given activation\n",
    "\n",
    "    :param inputs: Input 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "    convolution).\n",
    "    :param activation: string, specifies activation function to use everywhere in the block\n",
    "    :param version: version of inception block, one of 'a', 'b' (case sensitive)\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version, if this type of block is chosen\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of an inception block, given inputs\n",
    "    \"\"\"\n",
    "\n",
    "    assert filters % 16 == 0\n",
    "\n",
    "    # checking that the allowed version names did not change in ALLOWED_PARS\n",
    "    if allowed_pars != {}:\n",
    "        assert allowed_pars.get('information_block').get('inception').get('v1') == ['a', 'b']\n",
    "    # keep version argument if need to use without PARS\n",
    "    assert version in ['a', 'b']\n",
    "    # setting the version from pars\n",
    "    if pars.get('information_block').get('inception').get('v1') is not None:\n",
    "        version = pars.get('information_block').get('inception').get('v1')\n",
    "\n",
    "    assert activation in ['relu', 'elu', None]\n",
    "    # actv is a function, not a string, like activation\n",
    "    actv = activation == 'relu' and (lambda: LeakyReLU(0.0)) or activation == 'elu' and (lambda: ELU(1.0)) or None\n",
    "\n",
    "    # vertical 1\n",
    "    if version == 'a':\n",
    "        c1 = Conv2D(filters=filters // 8, kernel_size=(5, 5), padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    else:\n",
    "        c1_1 = Conv2D(filters=filters // 16, kernel_size=(1, 1), padding='same',\n",
    "                      activation=activation, kernel_initializer='he_normal')(inputs)\n",
    "        c1 = Conv2D(filters=filters // 8, kernel_size=(5, 5), padding='same', kernel_initializer='he_normal')(c1_1)\n",
    "\n",
    "    # vertical 2\n",
    "    if version == 'a':\n",
    "        c2 = Conv2D(filters=filters // 2, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    else:\n",
    "        c2_1 = Conv2D(filters=filters // 8 * 3, kernel_size=(1, 1), padding='same',\n",
    "                      activation=activation, kernel_initializer='he_normal')(inputs)\n",
    "        c2 = Conv2D(filters=filters // 2, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')(c2_1)\n",
    "\n",
    "    # vertical 3\n",
    "    p3_1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    if version == 'b':\n",
    "        c3 = Conv2D(filters=filters // 8, kernel_size=(1, 1), padding='same', kernel_initializer='he_normal')(p3_1)\n",
    "    else:\n",
    "        c3 = p3_1\n",
    "\n",
    "    # vertical 4\n",
    "    c4_1 = Conv2D(filters=filters // 4, kernel_size=(1, 1), padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    c4 = c4_1\n",
    "\n",
    "    # concatenating verticals together, normalizing and applying activation\n",
    "    result = concatenate([c1, c2, c3, c4], axis=3)\n",
    "    result = BatchNormalization(axis=3)(result)\n",
    "    result = actv()(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def inception_block_v2(inputs, filters, activation=None, version='b', pars={}, allowed_pars={}):\n",
    "    \"\"\"Create a version of v1 inception block described in:\n",
    "    https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202\n",
    "\n",
    "    Create an inception block described in v2, sections 'a', 'b', or 'c'\n",
    "    Each version has 4 verticals in their structure. See the link above.\n",
    "\n",
    "    For all versions, verticals 1 and 2 of the block start with 2D convolution, which:\n",
    "        reduces the number of input filters to next convolutions (to make computation cheaper)\n",
    "        uses (1, 1) kernels, no Normalization\n",
    "        is NOT normalized\n",
    "        is followed by specified activation\n",
    "    For all versions, verticals 1, 2, 3:\n",
    "        the middle convolutions use NConv2D with given activation, see its docstring\n",
    "        the final convolution layer is not normalised and not activated since it will be dene after concatenation\n",
    "    Vertical 4 is just a Conv2D. Its gets normalized and activated after being concatenated with\n",
    "        outputs of other verticals.\n",
    "    The concatenated output of the verticals is normalised and then activated with a given activation\n",
    "\n",
    "    :param inputs: Input 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "                    convolution).\n",
    "    :param activation: string, specifies activation function to use everywhere in the block\n",
    "    :param version: version of inception block, one of 'a', 'b', 'c' (case sensitive)\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version, if this type of block is chosen\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of an inception block, given inputs\n",
    "    \"\"\"\n",
    "    assert filters % 16 == 0\n",
    "\n",
    "    # checking that the allowed version names did not change in ALLOWED_PARS\n",
    "    if allowed_pars != {}:\n",
    "        assert allowed_pars.get('information_block').get('inception').get('v2') == ['a', 'b', 'c']\n",
    "    # keep version argument if need to use without PARS\n",
    "    assert version in ['a', 'b', 'c']\n",
    "    # setting the version from pars\n",
    "    if pars.get('information_block').get('inception').get('v2') is not None:\n",
    "        version = pars.get('information_block').get('inception').get('v2')\n",
    "\n",
    "    assert activation in ['relu', 'elu', None]\n",
    "    # actv is a function, not a string, like activation\n",
    "    actv = activation == 'relu' and (lambda: LeakyReLU(0.0)) or activation == 'elu' and (lambda: ELU(1.0)) or None\n",
    "\n",
    "    # vertical 1\n",
    "    c1_1 = Conv2D(filters=filters // 16, kernel_size=(1, 1), padding='same',\n",
    "                  activation=activation, kernel_initializer='he_normal')(inputs)\n",
    "    if version == 'a':\n",
    "        c1_2 = NConv2D(filters=filters // 8, kernel_size=3, padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c1_1)\n",
    "        c1 = Conv2D(filters=filters // 8, kernel_size=3, padding='same', kernel_initializer='he_normal')(c1_2)\n",
    "    elif version == 'b':\n",
    "        c1_2 = NConv2D(filters=filters // 8, kernel_size=(1, 3), padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c1_1)\n",
    "        c1_3 = NConv2D(filters=filters // 8, kernel_size=(3, 1), padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c1_2)\n",
    "        c1_4 = NConv2D(filters=filters // 8, kernel_size=(1, 3), padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c1_3)\n",
    "        c1 = Conv2D(filters=filters // 8, kernel_size=(3, 1), padding='same', kernel_initializer='he_normal')(c1_4)\n",
    "    else:\n",
    "        c1_2 = NConv2D(filters=filters // 8, kernel_size=(1, 3), padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c1_1)\n",
    "        c1_3 = NConv2D(filters=filters // 8, kernel_size=3, padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c1_2)\n",
    "        c1_41 = Conv2D(filters=filters // 8, kernel_size=(1, 3), padding='same', kernel_initializer='he_normal')(c1_3)\n",
    "        c1_42 = Conv2D(filters=filters // 8, kernel_size=(3, 1), padding='same', kernel_initializer='he_normal')(c1_3)\n",
    "        c1 = concatenate([c1_41, c1_42], axis=3)\n",
    "\n",
    "    # vertical 2\n",
    "    c2_1 = Conv2D(filters=filters // 8 * 3, kernel_size=(1, 1), padding='same',\n",
    "                  activation=activation, kernel_initializer='he_normal')(inputs)\n",
    "    if version == 'a':\n",
    "        c2 = Conv2D(filters=filters // 2, kernel_size=(3, 3), padding='same', kernel_initializer='he_normal')(c2_1)\n",
    "    elif version == 'b':\n",
    "        c2_2 = NConv2D(filters=filters // 2, kernel_size=(1, 3), padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c2_1)\n",
    "        c2 = Conv2D(filters=filters // 2, kernel_size=(3, 1), padding='same', kernel_initializer='he_normal')(c2_2)\n",
    "    else:\n",
    "        c2_21 = Conv2D(filters=filters // 2, kernel_size=(1, 3), padding='same', kernel_initializer='he_normal')(c2_1)\n",
    "        c2_22 = Conv2D(filters=filters // 2, kernel_size=(3, 1), padding='same', kernel_initializer='he_normal')(c2_1)\n",
    "        c2 = concatenate([c2_21, c2_22], axis=3)\n",
    "\n",
    "    # vertical 3\n",
    "    p3_1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    c3 = Conv2D(filters=filters // 8, kernel_size=(1, 1), padding='same', kernel_initializer='he_normal')(p3_1)\n",
    "\n",
    "    # vertical 4\n",
    "    c4 = Conv2D(filters=filters // 4, kernel_size=(1, 1), padding='same', kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    # concatenating verticals together, normalizing and applying activation\n",
    "    result = concatenate([c1, c2, c3, c4], axis=3)\n",
    "    result = BatchNormalization(axis=3)(result)\n",
    "    result = actv()(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def inception_block_et(inputs, filters, activation='relu', version='b', pars={}, allowed_pars={}):\n",
    "    \"\"\"Create an inception block with 2 options.\n",
    "    For intuition read, parts v1 and v2:\n",
    "    https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202\n",
    "\n",
    "    Each version/option has 4 verticals in their structure. See the link above.\n",
    "    Default option: version='b'\n",
    "        Create an inception block close to one described in v2, but keeps 5 as a factor for some convolutions\n",
    "    Alternative option: version='a'\n",
    "        Create an inception block described in v1, section\n",
    "\n",
    "\n",
    "    Function author Edward Tyantov. That's why the name: inception_block_et.\n",
    "    My modifications\n",
    "\n",
    "        use version='a' instead of split=False\n",
    "        use version='b' instead of split=True\n",
    "\n",
    "        change default to version='b', aka split=True\n",
    "\n",
    "        swap: Conv2D -> BatchNormalization -> activation\n",
    "        to:   NConv2D blocks. See NConv2D documentation for them.\n",
    "\n",
    "        swap: Conv2D -> activation\n",
    "        to:   Conv2D -> Conv2D(activation=activation)\n",
    "\n",
    "        change the order of the verticals to coincide with v2_paper notation\n",
    "\n",
    "        change names of the outputs of the block verticals to c1, c2, c3, c4\n",
    "\n",
    "        use 'result' instead of 'res' to avoid confusion with residuals\n",
    "\n",
    "    :param inputs: Input 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "                    convolution).\n",
    "    :param activation: activation function to use everywhere in the block\n",
    "    :param version: version of inception block\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version, if this type of block is chosen\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of an inception block, given inputs\n",
    "    \"\"\"\n",
    "    assert filters % 16 == 0\n",
    "\n",
    "    # checking that the allowed version names did not change in ALLOWED_PARS\n",
    "    if allowed_pars != {}:\n",
    "        assert allowed_pars.get('information_block').get('inception').get('et') == ['a', 'b']\n",
    "    # keep version argument if need to use without PARS\n",
    "    assert version in ['a', 'b']\n",
    "    # setting the version from pars\n",
    "    if pars.get('information_block').get('inception').get('et') is not None:\n",
    "        version = pars.get('information_block').get('inception').get('et')\n",
    "\n",
    "    assert activation in ['relu', 'elu', None]\n",
    "    # actv is a function, not a string, like activation\n",
    "    actv = activation == 'relu' and (lambda: LeakyReLU(0.0)) or activation == 'elu' and (lambda: ELU(1.0)) or None\n",
    "\n",
    "    # vertical 1\n",
    "    c1_1 = Conv2D(filters=filters // 16, kernel_size=(1, 1), padding='same',\n",
    "                  activation=activation, kernel_initializer='he_normal')(inputs)\n",
    "    if version == 'b':\n",
    "        c1_2 = NConv2D(filters=filters // 8, kernel_size=(1, 5), padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c1_1)\n",
    "        c1 = Conv2D(filters=filters // 8, kernel_size=(5, 1), kernel_initializer='he_normal', padding='same')(c1_2)\n",
    "    else:\n",
    "        c1 = Conv2D(filters=filters // 8, kernel_size=(5, 5), kernel_initializer='he_normal', padding='same')(c1_1)\n",
    "\n",
    "    # vertical 2\n",
    "    c2_1 = Conv2D(filters=filters // 8 * 3, kernel_size=(1, 1), padding='same',\n",
    "                  activation=activation, kernel_initializer='he_normal')(inputs)\n",
    "    if version == 'b':\n",
    "        c2_2 = NConv2D(filters=filters // 2, kernel_size=(1, 3), padding='same',\n",
    "                       activation=activation, kernel_initializer='he_normal')(c2_1)\n",
    "        c2 = Conv2D(filters=filters // 2, kernel_size=(3, 1), kernel_initializer='he_normal', padding='same')(c2_2)\n",
    "    else:\n",
    "        c2 = Conv2D(filters=filters // 2, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c2_1)\n",
    "\n",
    "    # vertical 3\n",
    "    p3_1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    c3 = Conv2D(filters=filters // 8, kernel_size=(1, 1), padding='same', kernel_initializer='he_normal')(p3_1)\n",
    "\n",
    "    # vertical 4\n",
    "    c4 = Conv2D(filters=filters // 4, kernel_size=(1, 1), padding='same', kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    # concatenating verticals together, normalizing and applying activation\n",
    "    result = concatenate([c1, c2, c3, c4], axis=3)\n",
    "    result = BatchNormalization(axis=3)(result)\n",
    "    result = actv()(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# ======================================================================================================================\n",
    "# Combining blocks, allowing to use different blocks from before\n",
    "# ======================================================================================================================\n",
    "\n",
    "def pooling_block(inputs, filters, kernel_size=(3, 3), strides=(2, 2), padding='same', activation=None,\n",
    "                  pool_size=(2, 2), trainable=True, pars={}, allowed_pars={}):\n",
    "    \"\"\"Function returning the output of one of the pooling blocks.\n",
    "\n",
    "    Allows not to make different versions of the u-net in terms of how pooling operation is performed:\n",
    "        1) trainable (default): through NConv2D custom function, see its documentation\n",
    "        2) non-trainable (alternative): through MaxPooling operation\n",
    "\n",
    "    To get the expected behaviour when changing 'trainable' assert strides == pool_size\n",
    "\n",
    "    Parameters starting with p_ are only to be used for (trainable=False) MaxPooling2D\n",
    "    Parameters starting with c_ are only to be used for (trainable=True) MaxPooling2D\n",
    "\n",
    "    :param inputs: 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters:     NConv2D argument, filters\n",
    "    :param kernel_size: NConv2D argument, kernel_size\n",
    "    :param strides:     NConv2D argument, strides\n",
    "    :param padding:     NConv2D/MaxPooling2D argument, padding\n",
    "    :param activation:  NConv2D argument, activation\n",
    "    :param pool_size:   MaxPooling2D argument, pool_size\n",
    "\n",
    "    :param trainable: boolean specifying the version of a pooling block with default behaviour\n",
    "        trainable=True: NConv2D(inputs._keras_shape[3], kernel_size=kernel_size, strides=strides, padding=padding)(\n",
    "        inputs)\n",
    "        trainable=False: MaxPooling2D(pool_size=pool_size)(inputs)\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version of the block\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of a pooling block\n",
    "    \"\"\"\n",
    "    # checking that the allowed trainable parameters did not change in ALLOWED_PARS\n",
    "    if allowed_pars != {}:\n",
    "        assert allowed_pars.get('pooling_block').get('trainable') == [True, False]\n",
    "    # keep trainable argument if need to use without PARS\n",
    "    assert trainable in [True, False]\n",
    "\n",
    "    # setting the version from pars\n",
    "    if pars.get('pooling_block').get('trainable') is not None:\n",
    "        trainable = pars.get('pooling_block').get('trainable')\n",
    "\n",
    "    # returning block's output\n",
    "    if trainable:\n",
    "        return NConv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "                       padding=padding, activation=activation)(inputs)\n",
    "    else:\n",
    "        return MaxPooling2D(pool_size=pool_size, padding=padding)(inputs)\n",
    "\n",
    "\n",
    "def information_block(inputs, filters, kernel_size=(3, 3), padding='valid', activation=None,\n",
    "                      block='inception', block_type='v2', version='b', pars={}, allowed_pars={}):\n",
    "    \"\"\"Function returning the output of one of the information blocks.\n",
    "\n",
    "    :param inputs: 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "                    convolution).\n",
    "    :param kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution\n",
    "                        window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "    :param padding: one of 'valid' or 'same' (case-insensitive), 'valid' by default to have the same as Conv2D\n",
    "    :param activation: string, specifies activation function to use everywhere in the block\n",
    "\n",
    "    Next 3 parameters are there to be able to leave 'pars' and 'allowed_pars' empty\n",
    "    :param block:       one of 'inception' or 'convolution' (case-sensitive)\n",
    "    :param block_type:  if block == 'inception', one of 'v1', 'v2', 'et' (case-sensitive)\n",
    "                        if block == 'convolution': one of 'simple', 'dilated' (case-sensitive)\n",
    "    :param version:     version of a block to use\n",
    "\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version of the block\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of a information block\n",
    "    \"\"\"\n",
    "    # getting which block, block_type, version to use as the information block\n",
    "    if pars.get('information_block') is not None:\n",
    "        block = list(pars.get('information_block').keys())[0]\n",
    "        block_type = list(pars.get('information_block').get(block).keys())[0]\n",
    "        version = pars.get('information_block').get(block).get(block_type)\n",
    "\n",
    "    # inception block\n",
    "    if block == 'inception':\n",
    "        if block_type == 'v1':\n",
    "            return inception_block_v1(inputs=inputs, filters=filters, activation=activation,\n",
    "                                      version=version, pars=pars, allowed_pars=allowed_pars)\n",
    "        elif block_type == 'v2':\n",
    "            return inception_block_v2(inputs=inputs, filters=filters, activation=activation,\n",
    "                                      version=version, pars=pars, allowed_pars=allowed_pars)\n",
    "        else:\n",
    "            return inception_block_et(inputs=inputs, filters=filters, activation=activation,\n",
    "                                      version=version, pars=pars, allowed_pars=allowed_pars)\n",
    "    # convolution block\n",
    "    else:\n",
    "        if block_type == 'simple':\n",
    "            return convolution_block(inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
    "                                     padding=padding, activation=activation,\n",
    "                                     version=version, pars=pars, allowed_pars=allowed_pars)\n",
    "        else:\n",
    "            return dilated_convolution_block(inputs=inputs, filters=filters,\n",
    "                                             kernel_size=kernel_size, padding=padding,\n",
    "                                             activation=activation, version=version,\n",
    "                                             pars=pars, allowed_pars=allowed_pars)\n",
    "\n",
    "\n",
    "def connection_block(inputs, filters, padding='valid', activation=None,\n",
    "                     version='residual', pars={}, allowed_pars={}):\n",
    "    \"\"\"Function returning the output of one of the connection block.\n",
    "\n",
    "    :param inputs: 4D tensor (samples, rows, cols, channels)\n",
    "    :param filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the\n",
    "                    convolution).\n",
    "    :param padding: one of 'valid' or 'same' (case-insensitive), 'valid' by default to have the same as Conv2D\n",
    "    :param activation:  string, one of 'elu' or 'relu' or None (case-sensitive),\n",
    "                        specifies activation function to use everywhere in the block\n",
    "\n",
    "    Version parameter is there to be able to leave 'pars' and 'allowed_pars' empty\n",
    "    :param version: one of 'not_residual' or 'residual', version of a block to use\n",
    "\n",
    "    :param pars: dictionary of parameters passed to u-net, determines the version of the block\n",
    "    :param allowed_pars: dictionary of all allowed to be passed to u-net parameters\n",
    "\n",
    "    :return: 4D tensor (samples, rows, cols, channels) output of a connection block\n",
    "    \"\"\"\n",
    "    # checking that the allowed trainable parameters did not change in ALLOWED_PARS\n",
    "    if allowed_pars != {}:\n",
    "        assert allowed_pars.get('connection_block') == ['not_residual', 'residual']\n",
    "    # keep trainable argument if need to use without PARS\n",
    "    assert version in ['not_residual', 'residual']\n",
    "    # setting the version from pars\n",
    "    if pars.get('connection_block') is not None:\n",
    "        version = pars.get('connection_block')\n",
    "\n",
    "    if version == 'residual':\n",
    "        return rblock(inputs=inputs, filters=32, kernel_size=(1, 1), padding='same', activation=activation)\n",
    "    else:\n",
    "        return Conv2D(filters=filters, kernel_size=(2, 2), padding=padding, kernel_initializer='he_normal')(inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, UpSampling2D, Dense\n",
    "from tensorflow.keras.layers import Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras import backend as K\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 80, 112\n",
    "K.set_image_data_format('channels_last')  # (number of images, rows per image, cols per image, channels)\n",
    "\n",
    "\n",
    "# ======================================================================================================================\n",
    "# U-net with Inception blocks, Normalised 2D Convolutions instead of Maxpooling\n",
    "# ======================================================================================================================\n",
    "\n",
    "def get_unet_customised(optimizer, pars=PARS, allowed_pars=ALLOWED_PARS):\n",
    "    \"\"\"\n",
    "    Creating and compiling the U-net\n",
    "\n",
    "    This version is fully customisable by choosing pars argument\n",
    "\n",
    "    :param optimizer: specifies the optimiser for the u-net, e.g. Adam, RMSProp, etc.\n",
    "    :param pars: optional, dictionary of parameters passed to customise the U-net\n",
    "    :param allowed_pars: optional, dictionary of parameters allowed to be passed to customise the U-net\n",
    "    :return: compiled u-net, Keras.Model object\n",
    "    \"\"\"\n",
    "\n",
    "    # string, activation function\n",
    "    activation = pars.get('activation')\n",
    "\n",
    "    # input\n",
    "    inputs = Input((IMG_ROWS, IMG_COLS, 1), name='main_input')\n",
    "    print('inputs:', inputs.shape)\n",
    "\n",
    "    #\n",
    "    # down the U-net\n",
    "    #\n",
    "\n",
    "    conv1 = information_block(inputs, 32, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv1', conv1.shape)\n",
    "    pool1 = pooling_block(inputs=conv1, filters=32, activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('pool1', pool1.shape)\n",
    "    pool1 = Dropout(0.5)(pool1)\n",
    "    print('pool1', pool1.shape)\n",
    "\n",
    "    conv2 = information_block(pool1, 64, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv2', conv2.shape)\n",
    "    pool2 = pooling_block(inputs=conv2, filters=64, activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('pool2', pool2.shape)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    print('pool2', pool2.shape)\n",
    "\n",
    "    conv3 = information_block(pool2, 128, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv3', conv3.shape)\n",
    "    pool3 = pooling_block(inputs=conv3, filters=128, activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('pool3', pool3.shape)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    print('pool3', pool3.shape)\n",
    "\n",
    "    conv4 = information_block(pool3, 256, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv4', conv4.shape)\n",
    "    pool4 = pooling_block(inputs=conv4, filters=256, activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('pool4', pool4.shape)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    print('pool4', pool4.shape)\n",
    "\n",
    "    #\n",
    "    # bottom level of the U-net\n",
    "    #\n",
    "    conv5 = information_block(pool4, 512, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv5', conv5.shape)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "    print('conv5', conv5.shape)\n",
    "\n",
    "    #\n",
    "    # auxiliary output for predicting probability of nerve presence\n",
    "    #\n",
    "    if pars['outputs'] == 2:\n",
    "        pre = Conv2D(1, kernel_size=(1, 1), kernel_initializer='he_normal', activation='sigmoid')(conv5)\n",
    "        pre = Flatten()(pre)\n",
    "        aux_out = Dense(1, activation='sigmoid', name='aux_output')(pre)\n",
    "\n",
    "    #\n",
    "    # up the U-net\n",
    "    #\n",
    "\n",
    "    after_conv4 = connection_block(conv4, 256, padding='same', activation=activation,\n",
    "                                   pars=pars, allowed_pars=allowed_pars)\n",
    "    print('after_conv4', after_conv4.shape)\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), after_conv4], axis=3)\n",
    "    conv6 = information_block(up6, 256, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv6', conv6.shape)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    print('conv6', conv6.shape)\n",
    "\n",
    "    after_conv3 = connection_block(conv3, 128, padding='same', activation=activation,\n",
    "                                   pars=pars, allowed_pars=allowed_pars)\n",
    "    print('after_conv3', after_conv3.shape)\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), after_conv3], axis=3)\n",
    "    conv7 = information_block(up7, 128, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv7', conv7.shape)\n",
    "    conv7 = Dropout(0.5)(conv7)\n",
    "    print('conv7', conv7.shape)\n",
    "\n",
    "    after_conv2 = connection_block(conv2, 64, padding='same', activation=activation, pars=pars,\n",
    "                                   allowed_pars=allowed_pars)\n",
    "    print('after_conv2', after_conv2.shape)\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), after_conv2], axis=3)\n",
    "    conv8 = information_block(up8, 64, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv8', conv8.shape)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    print('conv8', conv8.shape)\n",
    "\n",
    "    after_conv1 = connection_block(conv1, 32, padding='same', activation=activation,\n",
    "                                   pars=pars, allowed_pars=allowed_pars)\n",
    "    print('after_conv1', after_conv1.shape)\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), after_conv1], axis=3)\n",
    "    conv9 = information_block(up9, 32, padding='same', activation=activation, pars=pars, allowed_pars=allowed_pars)\n",
    "    print('conv9', conv9.shape)\n",
    "    conv9 = Dropout(0.5)(conv9)\n",
    "    print('conv9', conv9.shape)\n",
    "\n",
    "    # main output\n",
    "    conv10 = Conv2D(1, kernel_size=(1, 1), kernel_initializer='he_normal', activation='sigmoid', name='main_output')(\n",
    "        conv9)\n",
    "    print('conv10', conv10.shape)\n",
    "\n",
    "    # creating a model\n",
    "    # compiling the model\n",
    "    if pars['outputs'] == 1:\n",
    "        model = Model(inputs=inputs, outputs=conv10)\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss={'main_output': dice_coef_loss},\n",
    "                      metrics={'main_output': dice_coef})\n",
    "    else:\n",
    "        model = Model(inputs=inputs, outputs=[conv10, aux_out])\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss={'main_output': dice_coef_loss, 'aux_output': 'binary_crossentropy'},\n",
    "                      metrics={'main_output': dice_coef, 'aux_output': 'acc'},\n",
    "                      loss_weights={'main_output': 1., 'aux_output': 0.5})\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# get_unet() allows to try other versions of the u-net, if more are specified\n",
    "get_unet = get_unet_customised\n",
    "\n",
    "img_rows = IMG_ROWS\n",
    "img_cols = IMG_COLS\n",
    "\n",
    "# to check that model works without training, any kind of optimiser can be used\n",
    "model = get_unet(Adam(lr=1e-5), pars=PARS)\n",
    "\n",
    "x = np.random.random((1, img_rows, img_cols, 1))\n",
    "result = model.predict(x, 1)\n",
    "print(result)\n",
    "print('params', model.count_params())\n",
    "print('layer num', len(model.layers))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# # separate-module imports\n",
    "# from u_model import get_unet, IMG_COLS as img_cols, IMG_ROWS as img_rows\n",
    "# from data import load_train_data, load_test_data, load_nerve_presence\n",
    "# from configuration import PARS, OPTIMIZER\n",
    "\n",
    "\n",
    "def preprocess(imgs, to_rows=None, to_cols=None):\n",
    "    \"\"\"Resize all images in a 4D tensor of images of the shape (samples, rows, cols, channels).\n",
    "\n",
    "    :param imgs: a 4D tensor of images of the shape (samples, rows, cols, channels)\n",
    "    :param to_rows: new number of rows for images to be resized to\n",
    "    :param to_cols: new number of rows for images to be resized to\n",
    "    :return: a 4D tensor of images of the shape (samples, to_rows, to_cols, channels)\n",
    "    \"\"\"\n",
    "    if to_rows is None or to_cols is None:\n",
    "        to_rows = img_rows\n",
    "        to_cols = img_cols\n",
    "\n",
    "    print(imgs.shape)\n",
    "    imgs_p = np.ndarray((imgs.shape[0], to_rows, to_cols, imgs.shape[3]), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i, :, :, 0] = resize(imgs[i, :, :, 0], (to_rows, to_cols), preserve_range=True)\n",
    "    return imgs_p\n",
    "\n",
    "\n",
    "def train_and_predict():\n",
    "    print('-' * 30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-' * 30)\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "    imgs_present = load_nerve_presence()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    # centering and standardising the images\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)\n",
    "    std = np.std(imgs_train)\n",
    "    print(f\"Mean : {mean}\")\n",
    "    print(f\"STD : {std}\")\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to be in {0, 1} instead of {0, 255}\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-' * 30)\n",
    "\n",
    "    # load model - the Learning rate scheduler choice is most important here\n",
    "    model = get_unet(optimizer=OPTIMIZER, pars=PARS)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Fitting model...')\n",
    "    print('-' * 30)\n",
    "\n",
    "    if PARS['outputs'] == 1:\n",
    "        imgs_labels = imgs_mask_train\n",
    "    else:\n",
    "        imgs_labels = [imgs_mask_train, imgs_present]\n",
    "\n",
    "    model.fit(imgs_train, imgs_labels,\n",
    "              batch_size=32, epochs=50,\n",
    "              verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint, early_stopping])\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-' * 30)\n",
    "    imgs_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-' * 30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-' * 30)\n",
    "\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "\n",
    "    if PARS['outputs'] == 1:\n",
    "        np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "    else:\n",
    "        np.save('imgs_mask_test.npy', imgs_mask_test[0])\n",
    "        np.save('imgs_mask_test_present.npy', imgs_mask_test[1])\n",
    "\n",
    "train_and_predict()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from skimage.transform import resize\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "# # separate-module imports\n",
    "# from configuration import PARS\n",
    "# from data import load_test_ids, image_rows, image_cols, _dir\n",
    "\n",
    "def prep(img):\n",
    "    \"\"\"Prepare the image for to be used in a submission\n",
    "\n",
    "    :param img: 2D image\n",
    "    :return: resized version of an image\n",
    "    \"\"\"\n",
    "    img = img.astype('float32')\n",
    "    img = resize(img, (image_rows, image_cols), preserve_range=True)\n",
    "    img = (img > 0.5).astype(np.uint8)  # threshold\n",
    "    return img\n",
    "\n",
    "\n",
    "def run_length_enc(label):\n",
    "    \"\"\"Create a run-length-encoding of an image\n",
    "\n",
    "    :param label: image to be encoded\n",
    "    :return: string with run-length-encoding of an image\n",
    "    \"\"\"\n",
    "    x = label.transpose().flatten()\n",
    "    y = np.where(x > 0)[0]\n",
    "\n",
    "    # consider empty all masks with less than 10 pixels being greater than 0\n",
    "    if len(y) < 10:\n",
    "        return ''\n",
    "\n",
    "    z = np.where(np.diff(y) > 1)[0]\n",
    "    start = np.insert(y[z + 1], 0, y[0])\n",
    "    end = np.append(y[z], y[-1])\n",
    "    length = end - start\n",
    "    res = [[s + 1, l + 1] for s, l in zip(list(start), list(length))]\n",
    "    res = list(chain.from_iterable(res))\n",
    "    return ' '.join([str(r) for r in res])\n",
    "\n",
    "\n",
    "def submission():\n",
    "    \"\"\"Create a submission .csv file.\n",
    "\n",
    "    The file will have 2 cols: img, pixels.\n",
    "        The image column consists of the ids of test images.\n",
    "        The pixels column consists of the run-length-encodings of the corresponding images.\n",
    "    \"\"\"\n",
    "    imgs_id_test = load_test_ids()\n",
    "\n",
    "    print('Loading imgs_test from imgs_mask_test.npy')\n",
    "    imgs_test = np.load('imgs_mask_test.npy')\n",
    "    if PARS['outputs'] == 2:\n",
    "        print('Loading imgs_exist_test from imgs_mask_test_present.npy')\n",
    "        imgs_exist_test = np.load('imgs_mask_test_present.npy')\n",
    "\n",
    "    argsort = np.argsort(imgs_id_test)\n",
    "    imgs_id_test = imgs_id_test[argsort]\n",
    "    imgs_test = imgs_test[argsort]\n",
    "    if PARS['outputs'] == 2:\n",
    "        imgs_exist_test = imgs_exist_test[argsort]\n",
    "\n",
    "    total = imgs_test.shape[0]\n",
    "    ids = []\n",
    "    rles = []  # run-length-encodings\n",
    "    for i in range(total):\n",
    "        img = imgs_test[i, :, :, 0]\n",
    "        if PARS['outputs'] == 2:\n",
    "            img_exist = imgs_exist_test[i]\n",
    "        img = prep(img)\n",
    "\n",
    "        # only for version with 2 outputs\n",
    "        if PARS['outputs'] == 2:\n",
    "            # new probability of nerve presence\n",
    "            new_prob = (img_exist + min(1, np.sum(img) / 10000.0) * 5 / 3) / 2\n",
    "            # setting mask to array of zeros if new probability of nerve presence < 0.5\n",
    "            if np.sum(img) > 0 and new_prob < 0.5:\n",
    "                img = np.zeros((image_rows, image_cols))\n",
    "\n",
    "        # producing run-length encoded version of the image\n",
    "        rle = run_length_enc(img)\n",
    "\n",
    "        rles.append(rle)\n",
    "        ids.append(imgs_id_test[i])\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('{}/{}'.format(i, total))\n",
    "\n",
    "    # creating a submission file\n",
    "    file_name = os.path.join(_dir, 'submission_FP_32_1.csv')\n",
    "    with open(file_name, 'w+') as f:\n",
    "        f.write('img,pixels\\n')\n",
    "        for i in range(total):\n",
    "            s = str(ids[i]) + ',' + rles[i]\n",
    "            f.write(s + '\\n')\n",
    "\n",
    "submission()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.load_weights('weights.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_aware_model = quantize_model(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_aware_model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "                      loss={'quant_main_output': dice_coef_loss},\n",
    "                      metrics={'quant_main_output': dice_coef})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_aware_model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Quantization Aware Training\n",
    "\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# # separate-module imports\n",
    "# from u_model import get_unet, IMG_COLS as img_cols, IMG_ROWS as img_rows\n",
    "# from data import load_train_data, load_test_data, load_nerve_presence\n",
    "# from configuration import PARS, OPTIMIZER\n",
    "\n",
    "\n",
    "def QAT_train_and_predict(q_model):\n",
    "    print('-' * 30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-' * 30)\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "    imgs_present = load_nerve_presence()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    # centering and standardising the images\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)\n",
    "    std = np.std(imgs_train)\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to be in {0, 1} instead of {0, 255}\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-' * 30)\n",
    "\n",
    "    # load model - the Learning rate scheduler choice is most important here\n",
    "    #model = get_unet(optimizer=OPTIMIZER, pars=PARS)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint('q_weights.h5', monitor='val_loss', save_best_only=True)\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Fitting model...')\n",
    "    print('-' * 30)\n",
    "\n",
    "    if PARS['outputs'] == 1:\n",
    "        imgs_labels = imgs_mask_train\n",
    "    else:\n",
    "        imgs_labels = [imgs_mask_train, imgs_present]\n",
    "\n",
    "    q_model.fit(imgs_train, imgs_labels,\n",
    "              batch_size=32, epochs=50,\n",
    "              verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint, early_stopping])\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-' * 30)\n",
    "    imgs_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-' * 30)\n",
    "    q_model.load_weights('q_weights.h5')\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-' * 30)\n",
    "\n",
    "    imgs_mask_test = q_model.predict(imgs_test, verbose=1)\n",
    "\n",
    "    if PARS['outputs'] == 1:\n",
    "        np.save('imgs_mask_test_q_model.npy', imgs_mask_test)\n",
    "    else:\n",
    "        np.save('imgs_mask_test_q_model.npy', imgs_mask_test[0])\n",
    "        np.save('imgs_mask_test_present_q_model.npy', imgs_mask_test[1])\n",
    "\n",
    "QAT_train_and_predict(q_aware_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def QAT_submission():\n",
    "    \"\"\"Create a submission .csv file.\n",
    "\n",
    "    The file will have 2 cols: img, pixels.\n",
    "        The image column consists of the ids of test images.\n",
    "        The pixels column consists of the run-length-encodings of the corresponding images.\n",
    "    \"\"\"\n",
    "    imgs_id_test = load_test_ids()\n",
    "\n",
    "    print('Loading imgs_test from imgs_mask_test_q_model.npy')\n",
    "    imgs_test = np.load('imgs_mask_test_q_model.npy')\n",
    "    if PARS['outputs'] == 2:\n",
    "        print('Loading imgs_exist_test from imgs_mask_test_present.npy')\n",
    "        imgs_exist_test = np.load('imgs_mask_test_present_q_model.npy')\n",
    "\n",
    "    argsort = np.argsort(imgs_id_test)\n",
    "    imgs_id_test = imgs_id_test[argsort]\n",
    "    imgs_test = imgs_test[argsort]\n",
    "    if PARS['outputs'] == 2:\n",
    "        imgs_exist_test = imgs_exist_test[argsort]\n",
    "\n",
    "    total = imgs_test.shape[0]\n",
    "    ids = []\n",
    "    rles = []  # run-length-encodings\n",
    "    for i in range(total):\n",
    "        img = imgs_test[i, :, :, 0]\n",
    "        if PARS['outputs'] == 2:\n",
    "            img_exist = imgs_exist_test[i]\n",
    "        img = prep(img)\n",
    "\n",
    "        # only for version with 2 outputs\n",
    "        if PARS['outputs'] == 2:\n",
    "            # new probability of nerve presence\n",
    "            new_prob = (img_exist + min(1, np.sum(img) / 10000.0) * 5 / 3) / 2\n",
    "            # setting mask to array of zeros if new probability of nerve presence < 0.5\n",
    "            if np.sum(img) > 0 and new_prob < 0.5:\n",
    "                img = np.zeros((image_rows, image_cols))\n",
    "\n",
    "        # producing run-length encoded version of the image\n",
    "        rle = run_length_enc(img)\n",
    "\n",
    "        rles.append(rle)\n",
    "        ids.append(imgs_id_test[i])\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('{}/{}'.format(i, total))\n",
    "\n",
    "    # creating a submission file\n",
    "    file_name = os.path.join(_dir, 'submission_FP_32_QAT.csv')\n",
    "    with open(file_name, 'w+') as f:\n",
    "        f.write('img,pixels\\n')\n",
    "        for i in range(total):\n",
    "            s = str(ids[i]) + ',' + rles[i]\n",
    "            f.write(s + '\\n')\n",
    "\n",
    "QAT_submission()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_aware_model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q_aware_model.weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('QAT_INT8_Nerve_Segmentation.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def QAT_INT8_submission():\n",
    "    \"\"\"Create a submission .csv file.\n",
    "\n",
    "    The file will have 2 cols: img, pixels.\n",
    "        The image column consists of the ids of test images.\n",
    "        The pixels column consists of the run-length-encodings of the corresponding images.\n",
    "    \"\"\"\n",
    "    imgs_id_test = load_test_ids()\n",
    "\n",
    "    print('Loading imgs_test from imgs_mask_test.npy')\n",
    "    imgs_test = np.load('QAT_INT8_Predictions.npy')\n",
    "    if PARS['outputs'] == 2:\n",
    "        print('Loading imgs_exist_test from imgs_mask_test_present.npy')\n",
    "        imgs_exist_test = np.load('imgs_mask_test_present_q_model.npy')\n",
    "\n",
    "    argsort = np.argsort(imgs_id_test)\n",
    "    imgs_id_test = imgs_id_test[argsort]\n",
    "    imgs_test = imgs_test[argsort]\n",
    "    if PARS['outputs'] == 2:\n",
    "        imgs_exist_test = imgs_exist_test[argsort]\n",
    "\n",
    "    total = imgs_test.shape[0]\n",
    "    ids = []\n",
    "    rles = []  # run-length-encodings\n",
    "    for i in range(total):\n",
    "        img = imgs_test[i, :, :, 0]\n",
    "        if PARS['outputs'] == 2:\n",
    "            img_exist = imgs_exist_test[i]\n",
    "        img = prep(img)\n",
    "\n",
    "        # only for version with 2 outputs\n",
    "        if PARS['outputs'] == 2:\n",
    "            # new probability of nerve presence\n",
    "            new_prob = (img_exist + min(1, np.sum(img) / 10000.0) * 5 / 3) / 2\n",
    "            # setting mask to array of zeros if new probability of nerve presence < 0.5\n",
    "            if np.sum(img) > 0 and new_prob < 0.5:\n",
    "                img = np.zeros((image_rows, image_cols))\n",
    "\n",
    "        # producing run-length encoded version of the image\n",
    "        rle = run_length_enc(img)\n",
    "\n",
    "        rles.append(rle)\n",
    "        ids.append(imgs_id_test[i])\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('{}/{}'.format(i, total))\n",
    "\n",
    "    # creating a submission file\n",
    "    file_name = os.path.join(_dir, 'submission_INT8_QAT_1.csv')\n",
    "    with open(file_name, 'w+') as f:\n",
    "        f.write('img,pixels\\n')\n",
    "        for i in range(total):\n",
    "            s = str(ids[i]) + ',' + rles[i]\n",
    "            f.write(s + '\\n')\n",
    "\n",
    "QAT_INT8_submission()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "System_Python3.8",
   "language": "python",
   "name": "system_python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}